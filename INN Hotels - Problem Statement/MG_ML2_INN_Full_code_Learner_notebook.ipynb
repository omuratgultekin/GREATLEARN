{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Jm1-xjAGPAiY",
   "metadata": {
    "id": "Jm1-xjAGPAiY"
   },
   "source": [
    "<center><p float=\"center\">\n",
    "    <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/>\n",
    "</p></center>\n",
    "\n",
    "<center><font size=10>Artificial Intelligence and Machine Learning</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S1TV6s0qOhDa",
   "metadata": {
    "id": "S1TV6s0qOhDa"
   },
   "source": [
    "<center><img src=\"https://img.freepik.com/free-photo/luxury-bedroom-suite-resort-high-rise-hotel-with-working-table_105762-1783.jpg?w=740&t=st=1654505493~exp=1654506093~hmac=fc1167df2b3797e32400448b458fd80afb85e31403c7689e0b1506023ff754a7\" width=\"720\"></center>\n",
    "\n",
    "\n",
    "\n",
    "<center><font size=6>Hotel Booking Cancellation Prediction</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wLlUaoVgS5y1",
   "metadata": {
    "id": "wLlUaoVgS5y1"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-medicaid",
   "metadata": {
    "id": "dense-medicaid"
   },
   "source": [
    "### Context\n",
    "\n",
    "Many hotel bookings are called off due to cancellations or no-shows. The typical reasons for cancellations include change of plans, scheduling conflicts, etc. This is often made easier by the option to do so free of charge or preferably at a low cost, which benefits hotel guests. Still, it is a less desirable and possibly revenue-diminishing factor for hotels to deal with. Such losses are particularly high on last-minute cancellations.\n",
    "\n",
    "The new technologies involving online booking channels have dramatically changed customers\u2019 booking possibilities and behavior. This adds a further dimension to the challenge of how hotels handle cancellations, which are no longer limited to traditional booking and guest characteristics.\n",
    "\n",
    "\n",
    "The cancellation of bookings impacts a hotel on various fronts:\n",
    "1. Loss of resources (revenue) when the hotel cannot resell the room.\n",
    "2. Additional costs of distribution channels by increasing commissions or paying for publicity to help sell these rooms.\n",
    "3. Lowering prices last minute, so the hotel can resell a room, resulting in reducing the profit margin.\n",
    "4. Human resources to make arrangements for the guests.\n",
    "\n",
    "### Objective\n",
    "\n",
    "The increasing number of cancellations calls for a Machine Learning based solution that can help in predicting which booking is likely to be canceled. INN Hotels Group has a chain of hotels in Portugal, they are facing problems with the high number of booking cancellations and have reached out to your firm for data-driven solutions. You as a data scientist have to analyze the data provided to find which factors have a high influence on booking cancellations, build a predictive model that can predict which booking is going to be canceled in advance, and help in formulating profitable policies for cancellations and refunds.\n",
    "\n",
    "\n",
    "### Data Description\n",
    "\n",
    "The data contains the different attributes of customers' booking details. The detailed data dictionary is given below.\n",
    "\n",
    "\n",
    "**Data Dictionary**\n",
    "\n",
    "* Booking_ID: unique identifier of each booking\n",
    "* no_of_adults: Number of adults\n",
    "* no_of_children: Number of Children\n",
    "* no_of_weekend_nights: Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n",
    "* no_of_week_nights: Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n",
    "* type_of_meal_plan: Type of meal plan booked by the customer:\n",
    "    * Not Selected \u2013 No meal plan selected\n",
    "    * Meal Plan 1 \u2013 Breakfast\n",
    "    * Meal Plan 2 \u2013 Half board (breakfast and one other meal)\n",
    "    * Meal Plan 3 \u2013 Full board (breakfast, lunch, and dinner)\n",
    "* required_car_parking_space: Does the customer require a car parking space? (0 - No, 1- Yes)\n",
    "* room_type_reserved: Type of room reserved by the customer. The values are ciphered (encoded) by INN Hotels.\n",
    "* lead_time: Number of days between the date of booking and the arrival date\n",
    "* arrival_year: Year of arrival date\n",
    "* arrival_month: Month of arrival date\n",
    "* arrival_date: Date of the month\n",
    "* market_segment_type: Market segment designation.\n",
    "* repeated_guest: Is the customer a repeated guest? (0 - No, 1- Yes)\n",
    "* no_of_previous_cancellations: Number of previous bookings that were canceled by the customer prior to the current booking\n",
    "* no_of_previous_bookings_not_canceled: Number of previous bookings not canceled by the customer prior to the current booking\n",
    "* avg_price_per_room: Average price per day of the reservation; prices of the rooms are dynamic. (in euros)\n",
    "* no_of_special_requests: Total number of special requests made by the customer (e.g. high floor, view from the room, etc)\n",
    "* booking_status: Flag indicating if the booking was canceled or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tqfNqaJCQeEE",
   "metadata": {
    "id": "tqfNqaJCQeEE"
   },
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-calgary",
   "metadata": {
    "id": "proper-calgary"
   },
   "outputs": [],
   "source": [
    "# Code block for analysis/modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-rebel",
   "metadata": {
    "id": "fantastic-rebel"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mf_tDSWheqiz",
   "metadata": {
    "id": "Mf_tDSWheqiz"
   },
   "outputs": [],
   "source": [
    "# Code block for analysis/modeling\n",
    "hotel = pd.read_csv('INNHotelsGroup.csv')\n",
    "hotel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fD7H-dajQqyQ",
   "metadata": {
    "id": "fD7H-dajQqyQ"
   },
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Observations\n",
    "* Sanity checks"
   ],
   "metadata": {
    "id": "24EISH7e3Eka"
   },
   "id": "24EISH7e3Eka"
  },
  {
   "cell_type": "code",
   "source": [
    "# Code block for analysis/modeling\n",
    "print(hotel.info())\n",
    "print('--' * 20)\n",
    "print(hotel.describe().T)\n",
    "print('--' * 20)\n",
    "print(hotel.isnull().sum())\n",
    "print('--' * 20)\n",
    "print('Duplicate entries:', hotel.duplicated().sum())"
   ],
   "metadata": {
    "id": "Lu8MHZmk3GhC"
   },
   "id": "Lu8MHZmk3GhC",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "realistic-mortgage",
   "metadata": {
    "id": "realistic-mortgage"
   },
   "source": [
    "## <a name='link2'>Exploratory Data Analysis (EDA) Summary</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- EDA is an important part of any project involving data.\n",
    "- It is important to investigate and understand the data better before building a model with it.\n",
    "- A few questions have been mentioned below which will help you approach the analysis in the right manner and generate insights from the data.\n",
    "- A thorough analysis of the data, in addition to the questions mentioned below, should be done."
   ],
   "metadata": {
    "id": "1Ylg6CrY3Pqr"
   },
   "id": "1Ylg6CrY3Pqr"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EDA Observations:\n",
    "1. **Busiest Months**: October is the busiest month, followed by September. The number of bookings peaks during the autumn season.\n",
    "2. **Market Segments**: Online bookings constitute about 64% of the total, making it the primary revenue source.\n",
    "3. **Pricing**: Aviation and Online segments have the highest average room prices, while Complementary bookings are (as expected) near zero.\n",
    "4. **Cancellation Rate**: Approximately 32.7% of all bookings are canceled.\n",
    "5. **Special Requests**: Bookings with more special requests are significantly less likely to cancel. 100% of bookings with 3 or more requests were completed.\n",
    "6. **Repeated Guests**: Loyalty is a strong predictor; only ~1.7% of repeated guests cancel their stay."
   ],
   "metadata": {
    "id": "BOICppHq3RDT"
   },
   "id": "BOICppHq3RDT"
  },
  {
   "cell_type": "markdown",
   "id": "eda-questions-answers",
   "metadata": {},
   "source": [
    "### My Findings from the Exploratory Data Analysis:\n",
    "\n",
    "1. **When is the hotel busiest?**\n",
    "   - October is by far the busiest month with over 5,300 bookings. September and August are also quite packed, which suggests the late summer and autumn seasons are our peak times.\n",
    "\n",
    "2. **Where do our guests come from?**\n",
    "   - Most of our guests (about 64%) book through **Online** channels. Only about 29% are 'Offline' bookings.\n",
    "\n",
    "3. **How do prices change across market segments?**\n",
    "   - Online and Aviation segments are the most expensive (around 112\u20ac and 100\u20ac on average). Corporate and Offline bookings are more mid-range, while 'Complementary' bookings are near zero, as expected.\n",
    "\n",
    "4. **What's our overall cancellation rate?**\n",
    "   - Looking at the big picture, about **32.8%** of all bookings in this dataset ended up being canceled. That's nearly 1 in 3 bookings!\n",
    "\n",
    "5. **Do our regular guests cancel often?**\n",
    "   - Not at all! Only **1.7%** of repeating guests cancel. It turns out that once someone stays with us once, they are incredibly likely to show up for their next visit.\n",
    "\n",
    "6. **Do special requests help reduce cancellations?**\n",
    "   - Absolutely. There's a clear trend: the more special requests a guest makes, the less likely they are to cancel. In fact, guests with 3 or more requests had a 0% cancellation rate in our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda-calculations-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to find the answers to EDA questions\n",
    "\n",
    "print('1. Busiest Months (Top 5):')\n",
    "display(hotel['arrival_month'].value_counts().head())\n",
    "\n",
    "print('\\n2. Market Segment Distribution (%):')\n",
    "display(hotel['market_segment_type'].value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\n3. Average Price per Room by Market Segment:')\n",
    "display(hotel.groupby('market_segment_type')['avg_price_per_room'].mean().sort_values(ascending=False))\n",
    "\n",
    "print('\\n4. Overall Cancellation Rate (%):')\n",
    "display(hotel['booking_status'].value_counts(normalize=True) * 100)\n",
    "\n",
    "print('\\n5. Cancellation Rate by Repeating Guest status (%):')\n",
    "display(pd.crosstab(hotel['repeated_guest'], hotel['booking_status'], normalize='index') * 100)\n",
    "\n",
    "print('\\n6. Cancellation Rate by Number of Special Requests (%):')\n",
    "display(pd.crosstab(hotel['no_of_special_requests'], hotel['booking_status'], normalize='index') * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visual style\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "def labeled_countplot(data, feature, perc=False, n=None):\n",
    "    total = len(data[feature])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.countplot(data=data, x=feature, palette='viridis', order=data[feature].value_counts().index[:n])\n",
    "    for p in ax.patches:\n",
    "        if perc:\n",
    "            label = '{:.1f}%'.format(100 * p.get_height() / total)\n",
    "        else:\n",
    "            label = p.get_height()\n",
    "        ax.annotate(label, (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 9), textcoords='offset points')\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.show()\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\" Boxplot and histogram combined\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(nrows=2, sharex=True, gridspec_kw={'height_ratios': (.25, .75)}, figsize=figsize)\n",
    "    sns.boxplot(data=data, x=feature, ax=ax_box2, showmeans=True, color='violet')\n",
    "    sns.histplot(data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, color='teal') if bins else sns.histplot(data=data, x=feature, kde=kde, ax=ax_hist2, color='teal')\n",
    "    ax_hist2.axvline(data[feature].mean(), color='green', linestyle='--')\n",
    "    ax_hist2.axvline(data[feature].median(), color='black', linestyle='-')\n",
    "    plt.show()\n",
    "\n",
    "print('--- Univariate Analysis ---')\n",
    "histogram_boxplot(hotel, 'lead_time')\n",
    "histogram_boxplot(hotel, 'avg_price_per_room')\n",
    "labeled_countplot(hotel, 'market_segment_type', perc=True)\n",
    "labeled_countplot(hotel, 'type_of_meal_plan', perc=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visual style and functions (Restoring context for separate cell)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print('--- Bivariate Analysis ---')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=hotel, x='booking_status', y='lead_time', palette='magma')\n",
    "plt.title('Lead Time vs Booking Status')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=hotel, x='market_segment_type', y='avg_price_per_room', hue='booking_status')\n",
    "plt.title('Market Segment & Price vs Booking Status')\n",
    "plt.show()\n",
    "\n",
    "print('Correlation Heatmap:')\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(hotel.select_dtypes(include=np.number).corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "multivariate-eda",
   "metadata": {},
   "source": [
    "print('--- Multivariate Analysis ---')\n",
    "\n",
    "print('1. Average Price per Month across Market Segments:')\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.lineplot(data=hotel, x='arrival_month', y='avg_price_per_room', hue='market_segment_type', ci=None)\n",
    "plt.title('Average Price per Room across Months by Market Segment')\n",
    "plt.show()\n",
    "\n",
    "print('2. Lead Time vs Special Requests by Booking Status:')\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.boxplot(data=hotel, x='no_of_special_requests', y='lead_time', hue='booking_status')\n",
    "plt.title('Lead Time & Special Requests vs Booking Status')\n",
    "plt.show()\n",
    "\n",
    "print('3. Adults and Children vs Booking Status:')\n",
    "pd.crosstab([hotel['no_of_adults'], hotel['no_of_children']], hotel['booking_status'], normalize='index').plot(kind='bar', stacked=True, figsize=(15, 7))\n",
    "plt.title('Impact of Group Composition on Cancellation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Before we can dive into modeling, we need to get our data in shape. This step isn't just about cleaning; it's about making sure our algorithms (especially distance-based ones like KNN and SVM) can actually understand and learn from the features correctly.\n",
    "\n",
    "### Step 1: Cleaning Up (Feature Selection)\n",
    "- **Booking_ID:** This is just a unique label for each guest. Since it doesn't help us predict if someone will cancel, we're removing it to keep the model focused on what matters.\n",
    "\n",
    "### Step 2: Checking for Missing Info and Outliers\n",
    "- **Missing Values:** Luckily, our initial scan (`isnull().sum()`) showed that our data is complete with no empty cells. So, no filling-in needed here!\n",
    "- **Outliers:** We noticed some very high values in `lead_time` and `avg_price_per_room`. While these are unusual, they represent real scenarios (like someone booking a year in advance), so we're keeping them because they might be important clues for our model.\n",
    "\n",
    "### Step 3: Turning Words into Numbers (Encoding)\n",
    "- **The Goal (`booking_status`):** To make this computer-readable, we've changed 'Canceled' to **1** and 'Not_Canceled' to **0**.\n",
    "- **Categories:** For things like 'meal plan' or 'market segment', we used **One-Hot Encoding** (`pd.get_dummies`). This creates separate columns for each option so the model can treat them fairly.\n",
    "\n",
    "### Step 4: Leveling the Playing Field (Scaling)\n",
    "- **Why?** KNN and SVM care about 'distance'. If one feature (like price) is in the hundreds and another (like child count) is just 1 or 2, the price will unfairly dominate the model. We used `StandardScaler` to bring everything to the same scale (mean 0, variance 1).\n",
    "\n",
    "### Step 5: Splitting for Training and Testing\n",
    "- We set aside **70%** of the data to teach the model and kept **30%** hidden as a final 'test exam'.\n",
    "- By using `stratify=y`, we made sure the ratio of cancellations is the same in both sets, keeping our evaluation fair and balanced."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Drop Booking_ID\n",
    "df = hotel.drop(['Booking_ID'], axis=1)\n",
    "\n",
    "# Encode target variable\n",
    "df['booking_status'] = df['booking_status'].apply(lambda x: 1 if x == 'Canceled' else 0)\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['type_of_meal_plan', 'room_type_reserved', 'market_segment_type'], drop_first=True)\n",
    "\n",
    "# Split\n",
    "X = df.drop(['booking_status'], axis=1)\n",
    "y = df['booking_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Data Preprocessing complete.')"
   ],
   "metadata": {
    "id": "bKZ0AbiY3lMK"
   },
   "id": "bKZ0AbiY3lMK",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "Gh05O_jnS7CO",
   "metadata": {
    "id": "Gh05O_jnS7CO"
   },
   "source": [
    "### Model Evaluation Criterion\n",
    "\n",
    "Since the goal is to predict cancellations to help the hotel manage revenue, we need to balance:\n",
    "- **Recall**: Capturing as many actual cancellations as possible (to avoid lost revenue from empty rooms).\n",
    "- **Precision**: Avoiding false alarms (so the hotel doesn't overbook based on predicted cancellations that don't happen).\n",
    "\n",
    "We will focus on the **F1-Score** as a balanced metric, while also monitoring **Recall** closely."
   ]
  },
  {
   "cell_type": "code",
   "id": "cross-validation-logic",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def perform_cross_validation(model, X, y, cv=5):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='f1')\n",
    "    print(f'Average F1-Score: {scores.mean():.4f}')\n",
    "    print(f'Standard Deviation: {scores.std():.4f}')\n",
    "    return scores.mean()\n",
    "\n",
    "print('Cross-validation function defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-performance-func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_classification(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    # Predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # Creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"Accuracy\": acc,\n",
    "            \"Recall\": recall,\n",
    "            \"Precision\": precision,\n",
    "            \"F1\": f1,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    # Visualizing the confusion matrix\n",
    "    conf = confusion_matrix(target, pred)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.heatmap(conf, annot=True, fmt=\"g\", cmap='Blues')\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"Actual label\")\n",
    "    plt.show()\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6Zc_1ZkZNk7l",
   "metadata": {
    "id": "6Zc_1ZkZNk7l"
   },
   "source": [
    "### Model Evaluation Criterion"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize the KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit the model on scaled training data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate performance on training and test sets\n",
    "print('--- KNN PERFORMANCE ---')\n",
    "print('Training Performance:')\n",
    "model_performance_classification(knn, X_train_scaled, y_train)\n",
    "\n",
    "print('\\nTest Performance:')\n",
    "model_performance_classification(knn, X_test_scaled, y_test)\n",
    "\n"
   ],
   "metadata": {
    "id": "2Z57N_yM3soH"
   },
   "id": "2Z57N_yM3soH",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Thoughts on the KNN Model:\n",
    "- The KNN model is performing really well on both the training and test sets, which is great to see.\n",
    "- One thing I noticed is that the training score is a bit higher than the test score. This suggests the model might be sticking a bit too closely to the training data (a hint of overfitting).\n",
    "- Overall, it's impressive how well a distance-based approach can pick up the patterns in our hotel booking data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u6c4SAJ2JgC1",
   "metadata": {
    "id": "u6c4SAJ2JgC1"
   },
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize Gaussian Naive Bayes\n",
    "# Note: Scaling is not required for Naive Bayes as it's a probabilistic model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Fit the model on the original training data\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "print('--- NAIVE BAYES PERFORMANCE ---')\n",
    "print('Training Performance:')\n",
    "model_performance_classification(nb_model, X_train, y_train)\n",
    "\n",
    "print('\\nTest Performance:')\n",
    "model_performance_classification(nb_model, X_test, y_test)\n",
    "\n"
   ],
   "metadata": {
    "id": "5PJL0kMs32-0"
   },
   "id": "5PJL0kMs32-0",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Thoughts on the Naive Bayes Model:\n",
    "- This model is incredibly fast! It works almost instantly, making it a great baseline to start with.\n",
    "- However, looking at the F1-Score, it's clear that it struggles a bit compared to the other models.\n",
    "- This probably means that the features in our dataset aren't as independent as Naive Bayes assumes they are, but it's still a useful reference point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fb8QwpEISdP8",
   "metadata": {
    "id": "Fb8QwpEISdP8"
   },
   "source": [
    "###Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize SVM with probability=True to enable certain metrics\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Fit the model on scaled training data\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "print('--- SVM PERFORMANCE ---')\n",
    "print('Training Performance:')\n",
    "model_performance_classification(svm, X_train_scaled, y_train)\n",
    "\n",
    "print('\\nTest Performance:')\n",
    "model_performance_classification(svm, X_test_scaled, y_test)\n",
    "\n"
   ],
   "metadata": {
    "id": "MpztPmww35In"
   },
   "id": "MpztPmww35In",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Thoughts on the SVM Model:\n",
    "- The SVM model feels very stable. Its performance is balanced between catching actual cancellations (Recall) and being accurate when it predicts one (Precision).\n",
    "- The results for training and testing are very close to each other, which gives me confidence that this model will work well on new, unseen data.\n",
    "- Honestly, this looks like our strongest candidate so far. I'm curious to see if we can push it even further with some tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51T7JgSSUBLm",
   "metadata": {
    "id": "51T7JgSSUBLm"
   },
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-segment",
   "metadata": {
    "id": "monthly-segment"
   },
   "source": [
    "## Model Performance Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tune the models built in the Model Building section"
   ],
   "metadata": {
    "id": "KZiA-zQZd7kX"
   },
   "id": "KZiA-zQZd7kX"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "print('--- Tuning KNN ---')\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_knn.fit(X_train_scaled, y_train)\n",
    "knn_tuned = grid_knn.best_estimator_\n",
    "print('Best KNN:', grid_knn.best_params_)\n",
    "\n",
    "print('\\n--- Tuning Naive Bayes ---')\n",
    "param_grid_nb = {'var_smoothing': np.logspace(0, -9, num=20)}\n",
    "grid_nb = GridSearchCV(GaussianNB(), param_grid_nb, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_nb.fit(X_train, y_train)\n",
    "nb_tuned = grid_nb.best_estimator_\n",
    "print('Best NB:', grid_nb.best_params_)\n",
    "\n",
    "print('\\n--- Tuning SVM (Extra Optimized) ---')\n",
    "# Reducing sample size to 10% for much faster tuning\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "X_train_small, _, y_train_small, _ = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.9, random_state=42, stratify=y_train\n",
    ")\n",
    "grid_svm = RandomizedSearchCV(\n",
    "    SVC(probability=True, random_state=42, cache_size=2000, max_iter=10000), \n",
    "    param_grid_svm, \n",
    "    n_iter=3, \n",
    "    cv=3, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    verbose=2 # Added verbose to show progress\n",
    ")\n",
    "grid_svm.fit(X_train_small, y_train_small)\n",
    "svm_tuned = grid_svm.best_estimator_\n",
    "print('Best SVM:', grid_svm.best_params_)\n",
    "\n",
    "print('\\nFinal Training of Tuned SVM on Full Training Set...')\n",
    "# SVM fit on full data is the bottleneck. \n",
    "svm_tuned.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('\\nEvaluating Tuned SVM Performance on Test Set:')\n",
    "model_performance_classification(svm_tuned, X_test_scaled, y_test)"
   ],
   "metadata": {
    "id": "s9bxGIF_4C4d"
   },
   "id": "s9bxGIF_4C4d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "YIzaj5SZA7uy",
   "metadata": {
    "id": "YIzaj5SZA7uy"
   },
   "source": [
    "## Model Performance Comparison and Final Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "models = [knn, nb_model, svm, knn_tuned, nb_tuned, svm_tuned]\n",
    "model_names = ['KNN (Base)', 'NB (Base)', 'SVM (Base)', 'KNN (Tuned)', 'NB (Tuned)', 'SVM (Tuned)']\n",
    "\n",
    "results = []\n",
    "for name, model in zip(model_names, models):\n",
    "    if 'Tuned' in name or 'KNN' in name or 'SVM' in name:\n",
    "        # Use scaled data for KNN and SVM\n",
    "        preds = model.predict(X_test_scaled)\n",
    "        actual = y_test\n",
    "    else:\n",
    "        # Use original data for Naive Bayes base\n",
    "        preds = model.predict(X_test)\n",
    "        actual = y_test\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(actual, preds),\n",
    "        'Recall': recall_score(actual, preds),\n",
    "        'Precision': precision_score(actual, preds),\n",
    "        'F1 Score': f1_score(actual, preds)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "comparison_df = comparison_df.sort_values(by='F1 Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print('--- Final Model Comparison Summary Table ---')\n",
    "display(comparison_df)\n",
    "\n",
    "print('\\nFinal Observation: Tuning significantly improved the models, especially SVM/KNN.')"
   ],
   "metadata": {
    "id": "6Kj1kyrj4Kfz"
   },
   "id": "6Kj1kyrj4Kfz",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "final-model-selection-rationale",
   "metadata": {},
   "source": [
    "### Why I Chose the Tuned SVM as the Final Model\n",
    "\n",
    "After looking at all the results and comparing the models side-by-side, I've decided to go with the **Tuned SVM**. Here is the simple logic behind my choice:\n",
    "\n",
    "1.  **Finding the Right Balance (F1-Score):** In the hotel business, missing a cancellation costs money, but overbooking by mistake causes chaos. The Tuned SVM gave us the best 'middle ground' (the highest F1-Score) to handle both risks effectively.\n",
    "2.  **Reliability:** I really like that this model doesn't just memorize the training data. Its consistent performance on the test set shows it has actually learned the underlying 'why' behind cancellations.\n",
    "3.  **Handling Complex Data:** Our data has many different categories and some outliers. SVM is naturally good at handling this kind of complexity without getting confused, making it the most robust choice for INN Hotels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f_5Q1zMbZuut",
   "metadata": {
    "id": "f_5Q1zMbZuut"
   },
   "source": [
    "## Actionable Insights and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Key Things I Learned from the Data (Insights)\n",
    "\n",
    "After diving into the analysis, a few things really stood out about why guests cancel:\n",
    "\n",
    "1.  **The Wait Time Factor (Lead Time):** It's pretty clear: the earlier someone books, the more likely they are to change their mind. Long wait times mean more uncertainty.\n",
    "2.  **The Power of Personalization:** I found it fascinating that guests who make 3 or more special requests (like asking for a specific view) almost never cancel. It seems like once they start customizing their stay, they're much more committed to actually coming.\n",
    "3.  **Loyalty Matters:** Our repeated guests are incredibly reliable. Their cancellation rate is less than 2%, which makes them a 'safe bet' for revenue.\n",
    "4.  **Price Sensitivity:** Especially for online bookings, as the price goes up, so does the chance of a cancellation. Guests seem to be much pickier when they're paying a premium.\n",
    "5.  **Online Risks:** While most of our business comes from online channels, it's also where we see the most cancellations. It's a high-volume but high-risk area."
   ],
   "metadata": {
    "id": "SJHbcLym5tY5"
   },
   "id": "SJHbcLym5tY5"
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-increase",
   "metadata": {
    "id": "otherwise-increase"
   },
   "source": [
    "### Key Things I Learned from the Data (Insights)\n",
    "\n",
    "After diving into the analysis, a few things really stood out about why guests cancel:\n",
    "\n",
    "1.  **The Wait Time Factor (Lead Time):** It's pretty clear: the earlier someone books, the more likely they are to change their mind. Long wait times mean more uncertainty.\n",
    "2.  **The Power of Personalization:** I found it fascinating that guests who make 3 or more special requests (like asking for a specific view) almost never cancel. It seems like once they start customizing their stay, they're much more committed to actually coming.\n",
    "3.  **Loyalty Matters:** Our repeated guests are incredibly reliable. Their cancellation rate is less than 2%, which makes them a 'safe bet' for revenue.\n",
    "4.  **Price Sensitivity:** Especially for online bookings, as the price goes up, so does the chance of a cancellation. Guests seem to be much pickier when they're paying a premium.\n",
    "5.  **Online Risks:** While most of our business comes from online channels, it's also where we see the most cancellations. It's a high-volume but high-risk area."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Business Recommendations"
   ],
   "metadata": {
    "id": "ouQr3Kbc5sE5"
   },
   "id": "ouQr3Kbc5sE5"
  },
  {
   "cell_type": "markdown",
   "id": "marked-coaching",
   "metadata": {
    "id": "marked-coaching"
   },
   "source": [
    "### My Recommendations for the Hotel Team\n",
    "\n",
    "Based on what the data is telling us, here are some practical steps the hotel can take:\n",
    "\n",
    "1.  **Smart Capacity Planning:** Now that we have a high-accuracy SVM model, we can use it to 'overbook' just the right amount. If the model predicts a cancellation, we can safely re-sell that room in advance to keep the hotel at 100% capacity.\n",
    "2.  **Deposits for Early Birds:** Since long lead times are risky, we should consider requiring a non-refundable deposit for any booking made more than 2 months in advance, even if we offer a slightly better rate to balance it out.\n",
    "3.  **Encourage Special Requests:** Since special requests correlated with lower cancellations, we should proactively ask guests to pick a pillow type or floor preference shortly after they book. This small interaction can 'anchor' them to the reservation.\n",
    "4.  **Reward Our Regulars:** We should make life as easy as possible for repeated guests. Giving them perks like 'Zero Cancellation Fees' is a low-risk way to keep them coming back, since they rarely cancel anyway.\n",
    "5.  **Last-Minute Flash Sales:** For rooms that our model predicts will be canceled (especially in peak months like October), we can trigger automated 'Flash Sales' 48 hours before the arrival date to ensure we don't leave money on the table."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "f_5Q1zMbZuut"
   ],
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}